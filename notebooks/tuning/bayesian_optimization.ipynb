{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cc12a40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from sklearn.metrics import r2_score, mean_absolute_error\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from rich.console import Console\n",
    "from rich.table import Table\n",
    "from collections import Counter\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Integer, Categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00df71d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(r'C:\\SML_Projects\\SML_airplane_price_project')\n",
    "os.makedirs('results', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4116188c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/preprocessed/preprocessed_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8257d076",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 12377 entries, 0 to 12376\n",
      "Data columns (total 20 columns):\n",
      " #   Column                       Non-Null Count  Dtype  \n",
      "---  ------                       --------------  -----  \n",
      " 0   Model                        12377 non-null  float64\n",
      " 1   Year_of_Manufacture          12377 non-null  float64\n",
      " 2   Number_of_Engines            12377 non-null  float64\n",
      " 3   Engine_Type                  12377 non-null  float64\n",
      " 4   Capacity                     12377 non-null  float64\n",
      " 5   Range_(km)                   12377 non-null  int64  \n",
      " 6   Fuel_Consumption_(L/hour)    12377 non-null  float64\n",
      " 7   Hourly_Maintenance_Cost_($)  12377 non-null  float64\n",
      " 8   Age                          12377 non-null  float64\n",
      " 9   Sales_Region                 12377 non-null  float64\n",
      " 10  Price_($)                    12377 non-null  float64\n",
      " 11  Company                      12377 non-null  float64\n",
      " 12  Age_Group                    12377 non-null  float64\n",
      " 13  HMC_per_person               12377 non-null  float64\n",
      " 14  Engine_Power_Factor          12377 non-null  float64\n",
      " 15  Price_per_Seat               12377 non-null  float64\n",
      " 16  Seats_per_Engine             12377 non-null  float64\n",
      " 17  Company_Popularity           12377 non-null  float64\n",
      " 18  FuelCost_Maint_Index         12377 non-null  float64\n",
      " 19  Engine_to_Capacity           12377 non-null  float64\n",
      "dtypes: float64(19), int64(1)\n",
      "memory usage: 1.9 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1d90f1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.drop('Range_(km)', axis=1)   \n",
    "y = df['Range_(km)'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "63f24357",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a4469cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=3, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "60b6eeac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original train class distribution: Counter({5700: 1710, 14800: 1678, 6300: 1646, 3000: 1632, 15600: 1621, 1285: 1614})\n"
     ]
    }
   ],
   "source": [
    "print(\"Original train class distribution:\", Counter(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "96e1119d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor, BaggingRegressor, ExtraTreesRegressor, GradientBoostingRegressor, HistGradientBoostingRegressor, RandomForestRegressor, StackingRegressor, VotingRegressor\n",
    "from sklearn.linear_model import ElasticNet, Lasso, LinearRegression, Ridge\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "\n",
    "base_estimators = [\n",
    "    ('lr', LinearRegression()),\n",
    "    ('rf', RandomForestRegressor()),\n",
    "    ('et', ExtraTreesRegressor())\n",
    "]\n",
    "\n",
    "models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Lasso': Lasso(),\n",
    "    'Ridge': Ridge(),\n",
    "    'ElasticNet': ElasticNet(),\n",
    "    'Decision Tree': DecisionTreeRegressor(),\n",
    "    'Random Forest': RandomForestRegressor(),\n",
    "    'Gradient Boosting': GradientBoostingRegressor(),\n",
    "    'Extra Trees': ExtraTreesRegressor(),\n",
    "    'Hist Gradient Boosting': HistGradientBoostingRegressor(),\n",
    "    'SVR': SVR(),\n",
    "    'KNN': KNeighborsRegressor(),\n",
    "    'XGBoost': XGBRegressor(),\n",
    "    'LGBMRegressor': LGBMRegressor(),\n",
    "    'AdaBoost': AdaBoostRegressor(),\n",
    "    'Bagging': BaggingRegressor(),\n",
    "    'Voting': VotingRegressor(\n",
    "        estimators=base_estimators\n",
    "    ),\n",
    "    'Stacking': StackingRegressor(\n",
    "        estimators=base_estimators,\n",
    "        final_estimator=Ridge()\n",
    "    ),\n",
    "    'Bagged KNN': BaggingRegressor(\n",
    "        estimator=KNeighborsRegressor(),\n",
    "        n_estimators=10\n",
    "    ),\n",
    "    'Bagged DT': BaggingRegressor(\n",
    "        estimator=DecisionTreeRegressor(),\n",
    "        n_estimators=10\n",
    "    ),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1520a5de",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_spaces = {\n",
    "    'Linear Regression': {\n",
    "        'fit_intercept': Categorical([True, False]),\n",
    "        'positive': Categorical([True, False]),\n",
    "    },\n",
    "    \n",
    "    'Lasso': {\n",
    "        'alpha': Real(0.0001, 1.0, prior='log-uniform'),\n",
    "    },\n",
    "    'Ridge': {\n",
    "        'alpha': Real(0.1, 10.0, prior='log-uniform'),\n",
    "    },\n",
    "    'ElasticNet': {\n",
    "        'alpha': Real(0.0001, 1.0, prior='log-uniform'),\n",
    "        'l1_ratio': Real(0.0, 1.0)\n",
    "    },\n",
    "    'Decision Tree': {\n",
    "        'max_depth': Integer(2, 20),\n",
    "        'min_samples_split': Integer(2, 20)\n",
    "    },\n",
    "    'Extra Trees': {\n",
    "        'n_estimators': Integer(50, 200),\n",
    "        'max_depth': Integer(2, 20),\n",
    "        'min_samples_split': Integer(2, 20)\n",
    "    },\n",
    "    'Random Forest': {\n",
    "        'n_estimators': Integer(100, 500),\n",
    "        'max_depth': Integer(3, 30),\n",
    "        'min_samples_split': Integer(2, 10),\n",
    "        'min_samples_leaf': Integer(1, 4),\n",
    "        'max_features': Categorical(['sqrt', 'log2', None])\n",
    "    },\n",
    "\n",
    "    'Bagging': {\n",
    "        'n_estimators': Integer(10, 100),\n",
    "        'max_samples': Real(0.3, 1.0),\n",
    "        'max_features': Real(0.5, 1.0)\n",
    "    },\n",
    "    'Gradient Boosting': {\n",
    "        'n_estimators': Integer(50, 200),\n",
    "        'learning_rate': Real(0.01, 0.2, prior='log-uniform'),\n",
    "        'max_depth': Integer(2, 10)\n",
    "    },\n",
    "    'Hist Gradient Boosting': {\n",
    "        'learning_rate': Real(0.01, 0.2, prior='log-uniform'),\n",
    "        'max_depth': Integer(2, 10),\n",
    "        'max_leaf_nodes': Integer(15, 255)\n",
    "    },\n",
    "    'AdaBoost': {\n",
    "        'n_estimators': Integer(50, 200),\n",
    "        'learning_rate': Real(0.01, 0.5, prior='log-uniform')\n",
    "    },\n",
    "    'KNN': {\n",
    "        'n_neighbors': Integer(3, 30),\n",
    "        'weights': Categorical(['uniform', 'distance'])\n",
    "    },\n",
    "    'SVR': {\n",
    "        'C': Real(0.1, 10, prior='log-uniform'),\n",
    "        'epsilon': Real(0.001, 1.0, prior='log-uniform'),\n",
    "        'kernel': Categorical(['rbf', 'linear', 'poly'])\n",
    "    },\n",
    "    'XGBoost': {\n",
    "        'n_estimators': Integer(50, 200),\n",
    "        'max_depth': Integer(2, 10),\n",
    "        'learning_rate': Real(0.01, 0.2, prior='log-uniform'),\n",
    "    },\n",
    "    'LGBMRegressor': {\n",
    "        'n_estimators': Integer(50, 200),\n",
    "        'max_depth': Integer(-1, 20),\n",
    "        'learning_rate': Real(0.01, 0.2, prior='log-uniform')\n",
    "    },\n",
    "    'Voting': {\n",
    "        # Linear Regression\n",
    "        'lr__fit_intercept': Categorical([True, False]),\n",
    "        'lr__positive': Categorical([True, False]),\n",
    "\n",
    "        # Random Forest\n",
    "        'rf__n_estimators': Integer(50, 300),\n",
    "        'rf__max_depth': Integer(2, 20),\n",
    "        'rf__max_features': Categorical(['sqrt', 'log2', None]),\n",
    "\n",
    "        # Extra Trees\n",
    "        'et__n_estimators': Integer(50, 300),\n",
    "        'et__max_depth': Integer(2, 20),\n",
    "        'et__min_samples_split': Integer(2, 20),\n",
    "    },\n",
    "    'Stacking': {\n",
    "        # Base models\n",
    "        'lr__fit_intercept': Categorical([True, False]),\n",
    "        'lr__positive': Categorical([True, False]),\n",
    "\n",
    "        'rf__n_estimators': Integer(50, 300),\n",
    "        'rf__max_depth': Integer(2, 20),\n",
    "        'rf__max_features': Categorical(['sqrt', 'log2', None]),\n",
    "\n",
    "        'et__n_estimators': Integer(50, 300),\n",
    "        'et__max_depth': Integer(2, 20),\n",
    "        'et__min_samples_split': Integer(2, 20),\n",
    "\n",
    "        # Final Estimator (Ridge)\n",
    "        'final_estimator__alpha': Real(0.1, 10.0, prior='log-uniform'),\n",
    "    },\n",
    "    'Bagged KNN': {\n",
    "        'n_estimators': Integer(10, 100),\n",
    "        'max_samples': Real(0.3, 1.0)\n",
    "    },\n",
    "    'Bagged DT': {\n",
    "        'n_estimators': Integer(10, 100),\n",
    "        'max_samples': Real(0.3, 1.0),\n",
    "        'max_features': Real(0.5, 1.0)\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "af9ed54c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Linear Regression...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\skopt\\optimizer\\optimizer.py:517: UserWarning: The objective has been evaluated at point [np.False_, np.True_] before, using random point [False, False]\n",
      "  warnings.warn(\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\skopt\\optimizer\\optimizer.py:517: UserWarning: The objective has been evaluated at point [np.True_, np.False_] before, using random point [True, False]\n",
      "  warnings.warn(\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\skopt\\optimizer\\optimizer.py:517: UserWarning: The objective has been evaluated at point [np.False_, np.False_] before, using random point [True, True]\n",
      "  warnings.warn(\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\skopt\\optimizer\\optimizer.py:517: UserWarning: The objective has been evaluated at point [np.False_, np.True_] before, using random point [False, False]\n",
      "  warnings.warn(\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\skopt\\optimizer\\optimizer.py:517: UserWarning: The objective has been evaluated at point [np.True_, np.False_] before, using random point [True, True]\n",
      "  warnings.warn(\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\skopt\\optimizer\\optimizer.py:517: UserWarning: The objective has been evaluated at point [np.False_, np.True_] before, using random point [True, True]\n",
      "  warnings.warn(\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\skopt\\optimizer\\optimizer.py:517: UserWarning: The objective has been evaluated at point [np.True_, np.False_] before, using random point [True, True]\n",
      "  warnings.warn(\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\skopt\\optimizer\\optimizer.py:517: UserWarning: The objective has been evaluated at point [np.True_, np.False_] before, using random point [False, False]\n",
      "  warnings.warn(\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\skopt\\optimizer\\optimizer.py:517: UserWarning: The objective has been evaluated at point [np.False_, np.True_] before, using random point [True, True]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Lasso...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.816e+08, tolerance: 2.982e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Ridge...\n",
      "Training ElasticNet...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.820e+08, tolerance: 2.982e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Decision Tree...\n",
      "Training Random Forest...\n",
      "Training Gradient Boosting...\n",
      "Training Extra Trees...\n",
      "Training Hist Gradient Boosting...\n",
      "Training SVR...\n",
      "Training KNN...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\skopt\\optimizer\\optimizer.py:517: UserWarning: The objective has been evaluated at point [np.int64(3), np.str_('uniform')] before, using random point [np.int64(28), 'distance']\n",
      "  warnings.warn(\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\skopt\\optimizer\\optimizer.py:517: UserWarning: The objective has been evaluated at point [np.int64(3), np.str_('uniform')] before, using random point [np.int64(5), 'distance']\n",
      "  warnings.warn(\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\skopt\\optimizer\\optimizer.py:517: UserWarning: The objective has been evaluated at point [np.int64(3), np.str_('uniform')] before, using random point [np.int64(11), 'uniform']\n",
      "  warnings.warn(\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\skopt\\optimizer\\optimizer.py:517: UserWarning: The objective has been evaluated at point [np.int64(3), np.str_('uniform')] before, using random point [np.int64(25), 'distance']\n",
      "  warnings.warn(\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\skopt\\optimizer\\optimizer.py:517: UserWarning: The objective has been evaluated at point [np.int64(3), np.str_('uniform')] before, using random point [np.int64(12), 'uniform']\n",
      "  warnings.warn(\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\skopt\\optimizer\\optimizer.py:517: UserWarning: The objective has been evaluated at point [np.int64(3), np.str_('uniform')] before, using random point [np.int64(12), 'uniform']\n",
      "  warnings.warn(\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\skopt\\optimizer\\optimizer.py:517: UserWarning: The objective has been evaluated at point [np.int64(3), np.str_('uniform')] before, using random point [np.int64(24), 'distance']\n",
      "  warnings.warn(\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\skopt\\optimizer\\optimizer.py:517: UserWarning: The objective has been evaluated at point [np.int64(3), np.str_('uniform')] before, using random point [np.int64(14), 'uniform']\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training XGBoost...\n",
      "Training LGBMRegressor...\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000517 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1667\n",
      "[LightGBM] [Info] Number of data points in the train set: 9901, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 7798.079992\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training AdaBoost...\n",
      "Training Bagging...\n",
      "Training Voting...\n",
      "Training Stacking...\n",
      "Training Bagged KNN...\n",
      "Training Bagged DT...\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"Training {name}...\")\n",
    "\n",
    "    search_space = search_spaces[name]\n",
    "\n",
    "    bayes_search = BayesSearchCV(\n",
    "        estimator=model,\n",
    "        search_spaces=search_space,\n",
    "        n_iter=20,\n",
    "        scoring='r2',\n",
    "        cv=kf,\n",
    "        n_jobs=-1,\n",
    "        random_state=42,\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    bayes_search.fit(x_train, y_train)\n",
    "\n",
    "    best_model = bayes_search.best_estimator_\n",
    "    y_pred = best_model.predict(x_test)\n",
    "\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    scores = cross_val_score(best_model, x_train, y_train, cv=kf, scoring='r2', n_jobs=-1)\n",
    "\n",
    "    results.append([name, r2, mae, scores.mean(), scores.std()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "08597323",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                        Bayesian Optimization                        </span>\n",
       "┏━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━┳━━━━━━━━┳━━━━━━━━━━━━━┳━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Algorithm              </span>┃<span style=\"font-weight: bold\"> R2   </span>┃<span style=\"font-weight: bold\"> MAE    </span>┃<span style=\"font-weight: bold\"> K-Fold mean </span>┃<span style=\"font-weight: bold\"> K-Fold std </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━╇━━━━━━━━╇━━━━━━━━━━━━━╇━━━━━━━━━━━━┩\n",
       "│ <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Linear Regression</span>      │ <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">1.00</span> │ <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">0.00</span>   │        <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">1.00</span> │       <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">0.00</span> │\n",
       "├────────────────────────┼──────┼────────┼─────────────┼────────────┤\n",
       "│ Decision Tree          │ 1.00 │ 0.00   │        1.00 │       0.00 │\n",
       "├────────────────────────┼──────┼────────┼─────────────┼────────────┤\n",
       "│ Random Forest          │ 1.00 │ 0.00   │        1.00 │       0.00 │\n",
       "├────────────────────────┼──────┼────────┼─────────────┼────────────┤\n",
       "│ Gradient Boosting      │ 1.00 │ 0.00   │        1.00 │       0.00 │\n",
       "├────────────────────────┼──────┼────────┼─────────────┼────────────┤\n",
       "│ Hist Gradient Boosting │ 1.00 │ 0.00   │        1.00 │       0.00 │\n",
       "├────────────────────────┼──────┼────────┼─────────────┼────────────┤\n",
       "│ KNN                    │ 1.00 │ 0.00   │        1.00 │       0.00 │\n",
       "├────────────────────────┼──────┼────────┼─────────────┼────────────┤\n",
       "│ XGBoost                │ 1.00 │ 0.02   │        1.00 │       0.00 │\n",
       "├────────────────────────┼──────┼────────┼─────────────┼────────────┤\n",
       "│ LGBMRegressor          │ 1.00 │ 0.00   │        1.00 │       0.00 │\n",
       "├────────────────────────┼──────┼────────┼─────────────┼────────────┤\n",
       "│ AdaBoost               │ 1.00 │ 0.00   │        1.00 │       0.00 │\n",
       "├────────────────────────┼──────┼────────┼─────────────┼────────────┤\n",
       "│ Bagging                │ 1.00 │ 0.00   │        1.00 │       0.00 │\n",
       "├────────────────────────┼──────┼────────┼─────────────┼────────────┤\n",
       "│ Stacking               │ 1.00 │ 0.00   │        1.00 │       0.00 │\n",
       "├────────────────────────┼──────┼────────┼─────────────┼────────────┤\n",
       "│ Bagged KNN             │ 1.00 │ 0.00   │        1.00 │       0.00 │\n",
       "├────────────────────────┼──────┼────────┼─────────────┼────────────┤\n",
       "│ Bagged DT              │ 1.00 │ 0.00   │        1.00 │       0.00 │\n",
       "├────────────────────────┼──────┼────────┼─────────────┼────────────┤\n",
       "│ Extra Trees            │ 1.00 │ 0.01   │        1.00 │       0.00 │\n",
       "├────────────────────────┼──────┼────────┼─────────────┼────────────┤\n",
       "│ Voting                 │ 1.00 │ 0.02   │        1.00 │       0.00 │\n",
       "├────────────────────────┼──────┼────────┼─────────────┼────────────┤\n",
       "│ Ridge                  │ 1.00 │ 35.32  │        1.00 │       0.00 │\n",
       "├────────────────────────┼──────┼────────┼─────────────┼────────────┤\n",
       "│ SVR                    │ 1.00 │ 40.21  │        1.00 │       0.00 │\n",
       "├────────────────────────┼──────┼────────┼─────────────┼────────────┤\n",
       "│ Lasso                  │ 1.00 │ 160.13 │        1.00 │       0.00 │\n",
       "├────────────────────────┼──────┼────────┼─────────────┼────────────┤\n",
       "│ <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">ElasticNet</span>             │ <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">1.00</span> │ <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">160.16</span> │        <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">1.00</span> │       <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.00</span> │\n",
       "└────────────────────────┴──────┴────────┴─────────────┴────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                        Bayesian Optimization                        \u001b[0m\n",
       "┏━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━┳━━━━━━━━┳━━━━━━━━━━━━━┳━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mAlgorithm             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mR2  \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mMAE   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mK-Fold mean\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mK-Fold std\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━╇━━━━━━━━╇━━━━━━━━━━━━━╇━━━━━━━━━━━━┩\n",
       "│ \u001b[1;32mLinear Regression\u001b[0m      │ \u001b[1;32m1.00\u001b[0m │ \u001b[1;32m0.00\u001b[0m   │        \u001b[1;32m1.00\u001b[0m │       \u001b[1;32m0.00\u001b[0m │\n",
       "├────────────────────────┼──────┼────────┼─────────────┼────────────┤\n",
       "│ Decision Tree          │ 1.00 │ 0.00   │        1.00 │       0.00 │\n",
       "├────────────────────────┼──────┼────────┼─────────────┼────────────┤\n",
       "│ Random Forest          │ 1.00 │ 0.00   │        1.00 │       0.00 │\n",
       "├────────────────────────┼──────┼────────┼─────────────┼────────────┤\n",
       "│ Gradient Boosting      │ 1.00 │ 0.00   │        1.00 │       0.00 │\n",
       "├────────────────────────┼──────┼────────┼─────────────┼────────────┤\n",
       "│ Hist Gradient Boosting │ 1.00 │ 0.00   │        1.00 │       0.00 │\n",
       "├────────────────────────┼──────┼────────┼─────────────┼────────────┤\n",
       "│ KNN                    │ 1.00 │ 0.00   │        1.00 │       0.00 │\n",
       "├────────────────────────┼──────┼────────┼─────────────┼────────────┤\n",
       "│ XGBoost                │ 1.00 │ 0.02   │        1.00 │       0.00 │\n",
       "├────────────────────────┼──────┼────────┼─────────────┼────────────┤\n",
       "│ LGBMRegressor          │ 1.00 │ 0.00   │        1.00 │       0.00 │\n",
       "├────────────────────────┼──────┼────────┼─────────────┼────────────┤\n",
       "│ AdaBoost               │ 1.00 │ 0.00   │        1.00 │       0.00 │\n",
       "├────────────────────────┼──────┼────────┼─────────────┼────────────┤\n",
       "│ Bagging                │ 1.00 │ 0.00   │        1.00 │       0.00 │\n",
       "├────────────────────────┼──────┼────────┼─────────────┼────────────┤\n",
       "│ Stacking               │ 1.00 │ 0.00   │        1.00 │       0.00 │\n",
       "├────────────────────────┼──────┼────────┼─────────────┼────────────┤\n",
       "│ Bagged KNN             │ 1.00 │ 0.00   │        1.00 │       0.00 │\n",
       "├────────────────────────┼──────┼────────┼─────────────┼────────────┤\n",
       "│ Bagged DT              │ 1.00 │ 0.00   │        1.00 │       0.00 │\n",
       "├────────────────────────┼──────┼────────┼─────────────┼────────────┤\n",
       "│ Extra Trees            │ 1.00 │ 0.01   │        1.00 │       0.00 │\n",
       "├────────────────────────┼──────┼────────┼─────────────┼────────────┤\n",
       "│ Voting                 │ 1.00 │ 0.02   │        1.00 │       0.00 │\n",
       "├────────────────────────┼──────┼────────┼─────────────┼────────────┤\n",
       "│ Ridge                  │ 1.00 │ 35.32  │        1.00 │       0.00 │\n",
       "├────────────────────────┼──────┼────────┼─────────────┼────────────┤\n",
       "│ SVR                    │ 1.00 │ 40.21  │        1.00 │       0.00 │\n",
       "├────────────────────────┼──────┼────────┼─────────────┼────────────┤\n",
       "│ Lasso                  │ 1.00 │ 160.13 │        1.00 │       0.00 │\n",
       "├────────────────────────┼──────┼────────┼─────────────┼────────────┤\n",
       "│ \u001b[1;31mElasticNet\u001b[0m             │ \u001b[1;31m1.00\u001b[0m │ \u001b[1;31m160.16\u001b[0m │        \u001b[1;31m1.00\u001b[0m │       \u001b[1;31m0.00\u001b[0m │\n",
       "└────────────────────────┴──────┴────────┴─────────────┴────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "console = Console()\n",
    "\n",
    "results_sorted = sorted(results, key=lambda x: x[1], reverse=True)\n",
    "best_model = results_sorted[0]\n",
    "worst_model = results_sorted[-1]\n",
    "\n",
    "table = Table(title=\"Bayesian Optimization\", show_lines=True)\n",
    "table.add_column(\"Algorithm\")\n",
    "table.add_column(\"R2\")\n",
    "table.add_column(\"MAE\")\n",
    "table.add_column(\"K-Fold mean\", justify=\"right\")\n",
    "table.add_column(\"K-Fold std\", justify=\"right\")\n",
    "\n",
    "for row in results_sorted:\n",
    "    algo, r2, mae, kmean, kstd = row\n",
    "    if row == best_model:\n",
    "        table.add_row(f\"[bold green]{algo}[/bold green]\",\n",
    "                      f\"[bold green]{r2:.2f}[/bold green]\",\n",
    "                      f\"[bold green]{mae:.2f}[/bold green]\",\n",
    "                      f\"[bold green]{kmean:.2f}[/bold green]\",\n",
    "                      f\"[bold green]{kstd:.2f}[/bold green]\")\n",
    "    elif row == worst_model:\n",
    "        table.add_row(f\"[bold red]{algo}[/bold red]\",\n",
    "                      f\"[bold red]{r2:.2f}[/bold red]\",\n",
    "                      f\"[bold red]{mae:.2f}[/bold red]\",\n",
    "                      f\"[bold red]{kmean:.2f}[/bold red]\",\n",
    "                      f\"[bold red]{kstd:.2f}[/bold red]\")\n",
    "    else:\n",
    "        table.add_row(algo, f\"{r2:.2f}\", f\"{mae:.2f}\", f\"{kmean:.2f}\", f\"{kstd:.2f}\")\n",
    "\n",
    "console.print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8e42bbeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                        Bayesian Optimization                        </span>\n",
       "┏━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━┳━━━━━━━━┳━━━━━━━━━━━━━┳━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Algorithm              </span>┃<span style=\"font-weight: bold\"> R2   </span>┃<span style=\"font-weight: bold\"> MAE    </span>┃<span style=\"font-weight: bold\"> K-Fold mean </span>┃<span style=\"font-weight: bold\"> K-Fold std </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━╇━━━━━━━━╇━━━━━━━━━━━━━╇━━━━━━━━━━━━┩\n",
       "│ <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Linear Regression</span>      │ <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">1.00</span> │ <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">0.00</span>   │        <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">1.00</span> │       <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">0.00</span> │\n",
       "├────────────────────────┼──────┼────────┼─────────────┼────────────┤\n",
       "│ Decision Tree          │ 1.00 │ 0.00   │        1.00 │       0.00 │\n",
       "├────────────────────────┼──────┼────────┼─────────────┼────────────┤\n",
       "│ Random Forest          │ 1.00 │ 0.00   │        1.00 │       0.00 │\n",
       "├────────────────────────┼──────┼────────┼─────────────┼────────────┤\n",
       "│ Gradient Boosting      │ 1.00 │ 0.00   │        1.00 │       0.00 │\n",
       "├────────────────────────┼──────┼────────┼─────────────┼────────────┤\n",
       "│ Hist Gradient Boosting │ 1.00 │ 0.00   │        1.00 │       0.00 │\n",
       "├────────────────────────┼──────┼────────┼─────────────┼────────────┤\n",
       "│ KNN                    │ 1.00 │ 0.00   │        1.00 │       0.00 │\n",
       "├────────────────────────┼──────┼────────┼─────────────┼────────────┤\n",
       "│ XGBoost                │ 1.00 │ 0.02   │        1.00 │       0.00 │\n",
       "├────────────────────────┼──────┼────────┼─────────────┼────────────┤\n",
       "│ LGBMRegressor          │ 1.00 │ 0.00   │        1.00 │       0.00 │\n",
       "├────────────────────────┼──────┼────────┼─────────────┼────────────┤\n",
       "│ AdaBoost               │ 1.00 │ 0.00   │        1.00 │       0.00 │\n",
       "├────────────────────────┼──────┼────────┼─────────────┼────────────┤\n",
       "│ Bagging                │ 1.00 │ 0.00   │        1.00 │       0.00 │\n",
       "├────────────────────────┼──────┼────────┼─────────────┼────────────┤\n",
       "│ Stacking               │ 1.00 │ 0.00   │        1.00 │       0.00 │\n",
       "├────────────────────────┼──────┼────────┼─────────────┼────────────┤\n",
       "│ Bagged KNN             │ 1.00 │ 0.00   │        1.00 │       0.00 │\n",
       "├────────────────────────┼──────┼────────┼─────────────┼────────────┤\n",
       "│ Bagged DT              │ 1.00 │ 0.00   │        1.00 │       0.00 │\n",
       "├────────────────────────┼──────┼────────┼─────────────┼────────────┤\n",
       "│ Extra Trees            │ 1.00 │ 0.01   │        1.00 │       0.00 │\n",
       "├────────────────────────┼──────┼────────┼─────────────┼────────────┤\n",
       "│ Voting                 │ 1.00 │ 0.02   │        1.00 │       0.00 │\n",
       "├────────────────────────┼──────┼────────┼─────────────┼────────────┤\n",
       "│ Ridge                  │ 1.00 │ 35.32  │        1.00 │       0.00 │\n",
       "├────────────────────────┼──────┼────────┼─────────────┼────────────┤\n",
       "│ SVR                    │ 1.00 │ 40.21  │        1.00 │       0.00 │\n",
       "├────────────────────────┼──────┼────────┼─────────────┼────────────┤\n",
       "│ Lasso                  │ 1.00 │ 160.13 │        1.00 │       0.00 │\n",
       "├────────────────────────┼──────┼────────┼─────────────┼────────────┤\n",
       "│ <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">ElasticNet</span>             │ <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">1.00</span> │ <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">160.16</span> │        <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">1.00</span> │       <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">0.00</span> │\n",
       "└────────────────────────┴──────┴────────┴─────────────┴────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                        Bayesian Optimization                        \u001b[0m\n",
       "┏━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━┳━━━━━━━━┳━━━━━━━━━━━━━┳━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mAlgorithm             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mR2  \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mMAE   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mK-Fold mean\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mK-Fold std\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━╇━━━━━━━━╇━━━━━━━━━━━━━╇━━━━━━━━━━━━┩\n",
       "│ \u001b[1;32mLinear Regression\u001b[0m      │ \u001b[1;32m1.00\u001b[0m │ \u001b[1;32m0.00\u001b[0m   │        \u001b[1;32m1.00\u001b[0m │       \u001b[1;32m0.00\u001b[0m │\n",
       "├────────────────────────┼──────┼────────┼─────────────┼────────────┤\n",
       "│ Decision Tree          │ 1.00 │ 0.00   │        1.00 │       0.00 │\n",
       "├────────────────────────┼──────┼────────┼─────────────┼────────────┤\n",
       "│ Random Forest          │ 1.00 │ 0.00   │        1.00 │       0.00 │\n",
       "├────────────────────────┼──────┼────────┼─────────────┼────────────┤\n",
       "│ Gradient Boosting      │ 1.00 │ 0.00   │        1.00 │       0.00 │\n",
       "├────────────────────────┼──────┼────────┼─────────────┼────────────┤\n",
       "│ Hist Gradient Boosting │ 1.00 │ 0.00   │        1.00 │       0.00 │\n",
       "├────────────────────────┼──────┼────────┼─────────────┼────────────┤\n",
       "│ KNN                    │ 1.00 │ 0.00   │        1.00 │       0.00 │\n",
       "├────────────────────────┼──────┼────────┼─────────────┼────────────┤\n",
       "│ XGBoost                │ 1.00 │ 0.02   │        1.00 │       0.00 │\n",
       "├────────────────────────┼──────┼────────┼─────────────┼────────────┤\n",
       "│ LGBMRegressor          │ 1.00 │ 0.00   │        1.00 │       0.00 │\n",
       "├────────────────────────┼──────┼────────┼─────────────┼────────────┤\n",
       "│ AdaBoost               │ 1.00 │ 0.00   │        1.00 │       0.00 │\n",
       "├────────────────────────┼──────┼────────┼─────────────┼────────────┤\n",
       "│ Bagging                │ 1.00 │ 0.00   │        1.00 │       0.00 │\n",
       "├────────────────────────┼──────┼────────┼─────────────┼────────────┤\n",
       "│ Stacking               │ 1.00 │ 0.00   │        1.00 │       0.00 │\n",
       "├────────────────────────┼──────┼────────┼─────────────┼────────────┤\n",
       "│ Bagged KNN             │ 1.00 │ 0.00   │        1.00 │       0.00 │\n",
       "├────────────────────────┼──────┼────────┼─────────────┼────────────┤\n",
       "│ Bagged DT              │ 1.00 │ 0.00   │        1.00 │       0.00 │\n",
       "├────────────────────────┼──────┼────────┼─────────────┼────────────┤\n",
       "│ Extra Trees            │ 1.00 │ 0.01   │        1.00 │       0.00 │\n",
       "├────────────────────────┼──────┼────────┼─────────────┼────────────┤\n",
       "│ Voting                 │ 1.00 │ 0.02   │        1.00 │       0.00 │\n",
       "├────────────────────────┼──────┼────────┼─────────────┼────────────┤\n",
       "│ Ridge                  │ 1.00 │ 35.32  │        1.00 │       0.00 │\n",
       "├────────────────────────┼──────┼────────┼─────────────┼────────────┤\n",
       "│ SVR                    │ 1.00 │ 40.21  │        1.00 │       0.00 │\n",
       "├────────────────────────┼──────┼────────┼─────────────┼────────────┤\n",
       "│ Lasso                  │ 1.00 │ 160.13 │        1.00 │       0.00 │\n",
       "├────────────────────────┼──────┼────────┼─────────────┼────────────┤\n",
       "│ \u001b[1;31mElasticNet\u001b[0m             │ \u001b[1;31m1.00\u001b[0m │ \u001b[1;31m160.16\u001b[0m │        \u001b[1;31m1.00\u001b[0m │       \u001b[1;31m0.00\u001b[0m │\n",
       "└────────────────────────┴──────┴────────┴─────────────┴────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "temp_console = Console(record=True)\n",
    "temp_console.print(table)\n",
    "text = temp_console.export_text()\n",
    "with open('results/Tuning.txt', 'a', encoding='utf-8') as f:\n",
    "    f.write(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c51e198a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
